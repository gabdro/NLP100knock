{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 第8章: 機械学習\n",
    "\n",
    "本章では，Bo Pang氏とLillian Lee氏が公開しているMovie Review Dataのsentence polarity dataset v1.0を用い，文を肯定的（ポジティブ）もしくは否定的（ネガティブ）に分類するタスク（極性分析）に取り組む．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simplistic , silly and tedious . \r\n",
      "it's so laddish and juvenile , only teenage boys could possibly find it funny . \r\n",
      "exploitative and largely devoid of the depth or sophistication that would make watching such a graphic treatment of the crimes bearable . \r\n",
      "[garbus] discards the potential for pathological study , exhuming instead , the skewed melodrama of the circumstantial situation . \r\n",
      "a visually flashy but narratively opaque and emotionally vapid exercise in style and mystification . \r\n",
      "the story is also as unoriginal as they come , already having been recycled more times than i'd care to count . \r\n",
      "about the only thing to give the movie points for is bravado -- to take an entirely stale concept and push it through the audience's meat grinder one more time . \r\n",
      "not so much farcical as sour . \r\n",
      "unfortunately the story and the actors are served with a hack script . \r\n",
      "all the more disquieting for its relatively gore-free allusions to the serial murders , but it falls down in its attempts to humanize its subject . \r\n"
     ]
    }
   ],
   "source": [
    "!head  rt-polaritydata/rt-polaritydata/rt-polarity.neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 70. データの入手・整形\n",
    "文に関する極性分析の正解データを用い，以下の要領で正解データ（sentiment.txt）を作成せよ．\n",
    "\n",
    "1. rt-polarity.posの各行の先頭に\"+1 \"という文字列を追加する（極性ラベル\"+1\"とスペースに続けて肯定的な文の内容が続く）\n",
    "2. rt-polarity.negの各行の先頭に\"-1 \"という文字列を追加する（極性ラベル\"-1\"とスペースに続けて否定的な文の内容が続く）\n",
    "3. 上述1と2の内容を結合（concatenate）し，行をランダムに並び替える\n",
    "\n",
    "sentiment.txtを作成したら，正例（肯定的な文）の数と負例（否定的な文）の数を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input1 =\"rt-polarity.pos\"\n",
    "input2=\"rt-polarity.neg\"\n",
    "output=\"sentiment.txt\"\n",
    "\n",
    "words = []\n",
    "with open(input1, 'r') as pos:\n",
    "    words.extend(['+1 {}'.format(line.strip()) for line in pos])\n",
    "with open(input2, 'r') as neg:\n",
    "    words.extend(['+1 {}'.format(line.strip()) for line in neg])\n",
    "import random\n",
    "random.shuffle(words)\n",
    "\n",
    "with open(output, 'w') as file_out:\n",
    "    print(*words, sep='\\n', file=file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg> 5331\n"
     ]
    }
   ],
   "source": [
    "input1 =\"rt-polarity.neg\" #5332\n",
    "input2=\"rt-polarity.pos\" #5331\n",
    "#input1 = 'rt-polaritydata/rt-polaritydata/rt-polarity.pos'\n",
    "#input2 = 'rt-polaritydata/rt-polaritydata/rt-polarity.neg'\n",
    "output=\"sentiment.txt\"\n",
    "f = open(output,\"w\")\n",
    "words=[]\n",
    "for line in open(input1):\n",
    "    words.append(\"-1 \"+ line)\n",
    "    #writelines(\"-1 \"+line)\n",
    "print(\"neg>\",len(words))\n",
    "for line in open(input2):\n",
    "    words.append(\"+1 \"+ line)\n",
    "    #writelines(\"+1 \"+line)\n",
    "    \n",
    "import random\n",
    "random.shuffle(words)\n",
    "#出力\n",
    "for line in words:\n",
    "    print(line,end=\"\",file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import random\n",
    "\n",
    "fname_pos = 'rt-polaritydata/rt-polaritydata/rt-polarity.pos'\n",
    "fname_neg = 'rt-polaritydata/rt-polaritydata/rt-polarity.neg'\n",
    "fname_smt = 'sentiment.txt'\n",
    "fencoding = 'cp1252'        # Windows-1252らしい\n",
    "\n",
    "result = []\n",
    "\n",
    "# ポジティブデータの読み込み\n",
    "with codecs.open(fname_pos, 'r', fencoding) as file_pos:\n",
    "    result.extend(['+1 {}'.format(line.strip()) for line in file_pos])\n",
    "\n",
    "# ネガティブデータの読み込み\n",
    "with codecs.open(fname_neg, 'r', fencoding) as file_neg:\n",
    "    result.extend(['-1 {}'.format(line.strip()) for line in file_neg])\n",
    "\n",
    "# シャッフル\n",
    "random.shuffle(result)\n",
    "\n",
    "# 書き出し\n",
    "with codecs.open(fname_smt, 'w') as file_out:\n",
    "    print(*result, sep='\\n', file=file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+1 [anderson] uses a hit-or-miss aesthetic that hits often enough to keep the film entertaining even if none of it makes a lick of sense .\r\n",
      "-1 you might be shocked to discover that seinfeld's real life is boring .\r\n",
      "-1 needless to say , the dramatics that follow are utter hooey .\r\n",
      "+1 for the most part , it works beautifully as a movie without sacrificing the integrity of the opera .\r\n",
      "+1 grant carries the day with impeccable comic timing , raffish charm and piercing intellect .\r\n",
      "+1 you'll gasp appalled and laugh outraged and possibly , watching the spectacle of a promising young lad treading desperately in a nasty sea , shed an errant tear .\r\n",
      "-1 it's just weirdness for the sake of weirdness , and where human nature should be ingratiating , it's just grating .\r\n",
      "-1 it's provocative stuff , but the speculative effort is hampered by taylor's cartoonish performance and the film's ill-considered notion that hitler's destiny was shaped by the most random of chances .\r\n",
      "-1 [a] shapeless blob of desperate entertainment .\r\n",
      "+1 this is one of the year's best films .\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 sentiment.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: rt-polarity.neg: open: No such file or directory\n",
      "wc: rt-polarity.pos: open: No such file or directory\n",
      "   10662  234730 1260267 sentiment.txt\n"
     ]
    }
   ],
   "source": [
    "!wc rt-polarity.neg\n",
    "!wc rt-polarity.pos\n",
    "!wc sentiment.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10661  223947 1238405 sentiment.txt\r\n"
     ]
    }
   ],
   "source": [
    "!cat rt-polarity.pos rt-polarity.neg > sentiment.txt\n",
    "!wc sentiment.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5310 5299\n"
     ]
    }
   ],
   "source": [
    "pos_count,neg_count =0,0\n",
    "for line in open('sentiment.txt'):\n",
    "    if line[0:2]==\"+1\":\n",
    "        pos_count+=1\n",
    "    elif line[0:2] ==\"-1\":\n",
    "        neg_count+=1\n",
    "    else:\n",
    "        print(line)\n",
    "print(pos_count,neg_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 71. ストップワード\n",
    "英語のストップワードのリスト（ストップリスト）を適当に作成せよ．さらに，引数に与えられた単語（文字列）がストップリストに含まれている場合は真，それ以外は偽を返す関数を実装せよ．さらに，その関数に対するテストを記述せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "【stop word】あまりにたくさん検索にかかりすぎるので、検索精度の向上のためには検索対象から除外せざるを得ない語。助詞や助動詞などの機能語(日本語ならば「は」「の」「です」「ます」など、英語ならば「the」「of」「is」など)は、殆んどの場合これに該当する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "words=[]\n",
    "countA = Counter()\n",
    "for line in open('sentiment.txt'):\n",
    "    countA += Counter(line.split(\" \")[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP WORD:  ['.', '\\n', 'the', ',', 'a', 'and', 'of', 'to', 'is', 'in', 'that', 'it', 'as', 'but', 'with', 'film', 'for', 'this', 'its', 'an', 'movie', \"it's\", 'be', 'on', 'you', 'not', 'by', 'about', 'one', 'more']\n"
     ]
    }
   ],
   "source": [
    "stop_word=[]\n",
    "for i,j in countA.most_common(30):\n",
    "    stop_word.append(i)\n",
    "print(\"STOP WORD: \",stop_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (´･ω･｀)< sentiment.txtの頻度を調べてみた. \"movie\"とか頻出に入ってしまった(；´∀｀)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def include_stopword(word,stop_word):\n",
    "    if word in stop_word:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_stopword(\"Hello\",stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_stopword(\"not\",stop_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    ">ストップワード(stopword)  \n",
    "文書中の ”the”, ”is”, “have”, “take”など、\n",
    "話題の種類と関連を持たないと考えられる語。\n",
    "ストップワードをあらかじめ削除してからベクトル化を行うことが多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 72. 素性抽出\n",
    "極性分析に有用そうな素性を各自で設計し，学習データから素性を抽出せよ．素性としては，レビューからストップワードを除去し，各単語をステミング処理したものが最低限のベースラインとなるであろう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    ">ステミング(stemming)  \n",
    "同じような話題を指している語を一つの素性としてみなしたいとき、\n",
    "派生語なども含めて同一の素性とみなす作業のこと。\n",
    "例. ”run”, “runs”, “ran” さらに”runner”など。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    ">ポーターのステマー(Prter's stemmer)  \n",
    "英語のステミングの手法. 多くの規則がある.  \n",
    "規則例\n",
    "- 語尾のedを除去する(walked→walk)\n",
    "- 語尾のateを除去する(passionate→passion)\n",
    "- 語尾のationalを除去する(operational→oper)\n",
    "  \n",
    ">“operational”と ”operate”は同じ ”oper” として扱えるが、\n",
    "(hundred→hundr)となってしまったり、\n",
    "(international→intern)と、意味が変わってしまうこともある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.append(\",\")\n",
    "stopword_list.append(\".\")\n",
    "\n",
    "def extract_feature(filename=\"sentiment.txt\"):\n",
    "    target,feature = [],[]\n",
    "    x=[]\n",
    "    for line in open(filename):\n",
    "        words = line.strip(\"\\n\").split()\n",
    "        y = words[0]\n",
    "        for word in words[1:]:\n",
    "            word = stemmer.stem(word)\n",
    "            if not word in stopword_list:\n",
    "                x.append(word)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        target.append(int(y))\n",
    "        feature.append(x)\n",
    "        #init\n",
    "        x = []\n",
    "    return target,feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train , x_train = extract_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+1 [anderson] uses a hit-or-miss aesthetic that hits often enough to keep the film entertaining even if none of it makes a lick of sense .\r\n",
      "-1 you might be shocked to discover that seinfeld's real life is boring .\r\n",
      "-1 needless to say , the dramatics that follow are utter hooey .\r\n",
      "+1 for the most part , it works beautifully as a movie without sacrificing the integrity of the opera .\r\n",
      "+1 grant carries the day with impeccable comic timing , raffish charm and piercing intellect .\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 sentiment.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 73. 学習\n",
    "72で抽出した素性を用いて，ロジスティック回帰モデルを学習せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "x_list = []\n",
    "for line in x_train:\n",
    "    x_list.append(dict(Counter(line)))\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer()\n",
    "X = v.fit_transform(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 74. 予測\n",
    "73で学習したロジスティック回帰モデルを用い，与えられた文の極性ラベル（正例なら\"+1\"，負例なら\"-1\"）と，その予測確率を計算するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res = clf.predict(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10662"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10662  234730 1260267 sentiment.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc sentiment.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x15892 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v = DictVectorizer()\n",
    "X = v.fit_transform(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
